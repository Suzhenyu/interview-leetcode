### 项目问题因人而异，但是这些问题是共性的，可以思考一下

* 你最有成就感，或者最有挑战的项目经过，解决什么样的问题
* 数据量很大还是并发量很高，并发量体现在哪里？QPS是多少？
* 怎么提高可用性的？
* 技术难点体现在哪里？
* 你的项目有没有出现什么重大事故/故障，是怎么解决的，具体是什么原因
* 有没有什么印象深刻的Bug

### 分布式锁如何实现

分布式锁，一般为了达到分布式加锁需要通过投票的机制，依次向所有节点申请加锁，半数以上节点投票通过完成加锁，可以避免单点故障（Redis称为Redlock算法）

* 加锁的动作需要保证原子性，`Redis`通过`Lua`脚本来保证
* 谁加的锁谁来释放锁，所以需要标记锁来源
* 预防加锁程序挂掉导致的锁不释放，所以需要设置过期时间
* 加锁成功需要判断获取锁总耗时没有超过锁有效时间，这才判定为加锁成功

注意：假如程序处理速度比锁过期时间要长，是不合理的设计，超时时间的设置就很精细，一般都是远大于处理的时间，如果真的处理时间太长应该判定失败并告警

见[redis](interview/redis.md)

### 如何实现一个分布式id生成器

首先要知道自增主键出现的问题

* 在高并发的情况下加入事务执行失败回滚，会跳过当前插入`ID`，使`ID`不连续
* 所有数据库中的自增字段或者自增序列都要记录日志，会产生磁盘IO，会成为性能瓶颈
* 假如数据库使用的是Range分片，自增`ID`可能会集中写入集群中的一个节点，出现数据访问热地世，性能退化成单机写入

解决方案

* 随机主键`UUID`方案（32 个的 16 进制数字，16^32 = 2^128 就是128位），虽然可以保证每次随机都不一样，但缺点是键值长度过长，存储和计算的代价增加，uuid只能保证不重复，但数据页可能会分裂，影响查询性能
* 号段模式，每个业务批量获取数据库中的号段，比如一次获取1000个，然后内存生成1000个自增ID，使用完再获取1000个；只需要插入一条记录，步长设置为1000，注意使用乐观锁（维护版本号），记录字段有业务类型、当前最大可用id、号段步长，version号；缺点服务重启时重新申请号段，不够随机有被猜到的风险
* 在`TiDB` 里提供了一种`AutoRandom`的算法，生成64位整型随机`ID`，`1bit`符号位、`5bit`事务开始时间，`58bit`自增序列号，还是有可能出现尾部热点
* 雪花算法`Snowflake`，时间戳精确到毫秒，10位长度机器码最大规模1024个节点(2^10), 12位序列代表1毫秒能产生的id数量最多4096个。所以 `TPS` 可以达到 `419` 万左右（2^22*1000）, 每秒那么多大多系统都够了

![](res/2021-04-12-15-27-47.png)

注意雪花算法，对时间的要求比较高，如果时间不同步，时钟回拨时 `ID` 有可能出现重复

引用：[分布式数据库30讲](https://time.geekbang.org/column/article/285819)

### 如何优化雪花算法的问题

雪花算法的问题主要在于时间回拨出现`id`重复、机器id有上限

时钟回拨就是本机时间略快，完成时间服务器的校准（NTP或者闰秒回拨）以后，会出现时间倒退，导致生成ID重复

时钟回拨解决办法：
* 继续在当前ID序列号最大基础上增加，方案来自[snowflake算法的时钟回拨问题如何解决](https://blog.csdn.net/qq_37286668/article/details/107292527)
* 如果时间偏差比较小，`<=5ms` 可以等待2倍时间，牺牲很短时间的可用性，方案来自[SnowFlakeID原理和改进优化](https://www.ctolib.com/topics-143347.html)
* 时间回拨跨度太大时告警，并摘除本身节点，只会影响一个节点
* 也可以考虑直接关闭时间同步

机器id有上限的解决办法（雪花算法优化）
* 百度（uid-generator）的解决办法是可以自定义各部分的位数，工作机器`ID`需要数据库中创建一个表，插入机器相关信息（`host`和`port`），再根据表的自增`ID`作为`workID`，重启服务就另申请`workID`
* 美团使用`Leaf`算法，可以基于号段模式或雪花算法，对号段模式优化[双buffer方案](https://tech.meituan.com/2017/04/21/mt-leaf.html)，提前加载下一号段；雪花算法借助`zookeeper`的持久顺序节点的特性配置`workID`(我想上容器的话直接使用hostname或者使用k8s中的sts也不错)

注意雪花算法实际上是趋势递增，而不是绝对递增，这是为了保证性能

### 如何实现秒杀系统

漏斗的思路，是架构上设计，客户端，网关，后台服务，层层限流，保证业务处理不被流量洪峰打挂了

客户端侧降低服务端压力：
* 动静分离，静态资源放到cdn（某些服务为了更新及时不能放cdn）、前端文件`webpack`打包减少请求量
* 减少后端请求数量，只保留抢按钮的请求
* 时间使用客户端时间，不到时候无法点击
* 增加互动游戏再降低并发请求量
* 秒杀活动一旦发起，不允许修改详情等信息
* 保证web安全，防止xss与重放（随机数、时间戳、序列号）、CSRF等攻击方式

部署架构：
* 后端服务部署多个可用区，防止单可用区故障导致整体不可用
* 需要配置安全策略：防火墙、防DDOS、API网关、WAF；接入风控挡掉不合法请求
* 使用负载均衡SLB，根据不同节点负载情况分发流量
* 硬件上使用SSD

后端防护：
* 防止超卖，推动库存确认流程到支付阶段
* 库存信息放到内存中(redis)
* 使用另外的数据库集群

过载保护（有损保护）：
* 服务降级：秒杀期间关闭某些服务，比如淘宝关闭退款流程，微信抢红包延迟到账
* 熔断：接入监控系统，根据系统节点的承载能力和服务质量有关，比如 CPU 的使用率超过 90%，请求错误率超过 5%，请求延迟超过 500ms， 它们中的任意一个满足条件就会出现熔断，主动拒绝请求；
* 限流：速度过快时加入验证码流程，接入API网关可以进行流量控制，请求过滤和控制，并过滤的请求，前端根据错误码返回友好的页面（已抢完之类）常见限流算法：漏桶>令牌桶>滑动窗口>计数器


### 快速熟悉一个项目的方法

不知道你有没有经历过一个五年或者更长工作年限的开发人员半路加入团队的情况，可能第一两个星期他会问一些业务或者技术问题，不过一两个月他就可能在指导那些初级开发人员了。

什么原因呢？因为他已经从过往经验里面总结出来一些套路了。

### 项目的共性

1. 绝大部分业务系统，核心功能都是由增删改查组成，然后通过通信、运算和人机交互串起来的，系统的复杂度主要体现在系统规模、性能、稳定性、业务流程、通信等方面。（部分工具类、基础架构类系统可能不一样）
2. 绝大部份系统，都是遵循某种或几种设计模式分层进行开发的，最最常见的也就是MVC了。其他请参考一下设计模式教程。

### 快速熟悉新的项目的套路。

1. 先搞清楚新的系统是搞什么的，就问简单几个问题，谁在用这个系统？用这个系统做什么？然后自己根据这些问题去文档找答案。
2. 弄清楚系统是怎么分层、分模块的，每层、每个模块都用到了什么技术和框架，之间是怎么通信的。有架构设计文档的话学习一下最好，没用过的技术先查查资料知道个大概。
3. 把开发环境搭起来，通过几个典型的功能弄清楚系统里面增删改查、通信、用户交互是怎么实现的。最简单的方法是根据系统的分层，先从前端到数据库把代码疏通一下，搞不清楚的话打开debug模式一步一步走一下。
4. 经过上面三个步骤基本上就可以改几个bug和照葫芦画瓢做个功能了。后面重点关注那些没用过的技术和组件：先搞清它的目的、背景、实现原理和功能列表，再照着文档做几个demo，平常工作时把它的文档建个快捷方式，随手查询学习一下。
5. 平常开发过程中如果遇到问题首先要相信： 

  1）绝大部分自己遇到的问题很多人已经遇到过并且解决了 。 
  2）绝大部分自己遇到的问题在当前系统里面已经有了答案。 
  3）绝大部分自己遇到的问题在你用的框架和组件里面都有现成的解决方案。

6. 对于规模比较大的系统或者系统集合，其实你平时工作接触到的也就是其中的一个系统或者模块，先把自己接触的部分搞定就行了。

### 对于老系统要注意

对于老系统，首先建议看一下 [在感觉项目代码的构架不行的时候, 你们会怎么办?](https://www.zhihu.com/question/47283785/answer/105534222)

* 老系统其实满是宝藏，里面有很多你可以借鉴和学习的东西。
* 老系统也满是坑，一个看起来毫不悬念的代码改了以后可能会引发地震。
* 很多你看着不爽的代码其实都是有道理的。
* 不要在老系统里面继续挖坑。
* 看不懂的代码不要动。
* 在你力所能及的范围内让老系统变的更美好。

上面这个套路应该符合百分之七八十的项目，题主可以试试看。

引用：[程序员如何快速上手一个自己不太熟悉的新项目？有什么技巧？](https://www.zhihu.com/question/38865497)